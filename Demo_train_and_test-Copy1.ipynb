{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from models.resnet50 import ResNet50\n",
    "#get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "def parse_args():\n",
    "    import sys\n",
    "    sys.argv=['']\n",
    "    \"\"\"Parse input arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Training Image Classification Model')\n",
    "    parser.add_argument('--gpu', dest='gpu_id', help='GPU device id to use [0]',\n",
    "                        default='0')\n",
    "    parser.add_argument('--cpu', dest='cpu_mode',\n",
    "                        help='Use CPU mode (overrides --gpu)',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--model', dest='model', help='Network to use [resnet50]',\n",
    "                        default='resnet50_imagenet')\n",
    "    parser.add_argument('--pretrained', dest='pretrained', help='Pretrained Custom Network to use',\n",
    "                        default='pretrainedModel.h5')\n",
    "    parser.add_argument('--epochs', dest='epochs', help='Number of Epochs for Training',\n",
    "                        default=10, type=int)\n",
    "    parser.add_argument('--validation', dest='validation_split', help='Ratio of Validation Data',\n",
    "                        default=0.2, type=float)\n",
    "    parser.add_argument('--save', dest='save', help='Save Model File Name',\n",
    "                        default='resnet50.imagenet.h5')\n",
    "    parser.add_argument('--test', dest='test_model', help='Test Model',\n",
    "                        default=True, type=bool)\n",
    "    parser.add_argument('--train', dest='train_data', help='Training Data Dir',\n",
    "                        default='example_annotation')\n",
    "    parser.add_argument('--size', dest='img_size', help='Size of Input Images (default:224 -> 224x224x3)',\n",
    "                        default=224, type=int)\n",
    "    parser.add_argument('--mode', dest='mode', help='Classification or Regression mode',\n",
    "                        default='classification')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "def load_data(mode='train'):\n",
    "    data_path = os.path.join(os.getcwd(),'data',args.train_data)\n",
    "    text_file = os.path.join(data_path, 'annotation.txt')\n",
    "    if os.path.exists(text_file):\n",
    "        return load_data_from_annotation()\n",
    "    elif os.path.isdir(os.path.join(data_path, 'train')) and os.path.isdir(os.path.join(data_path, 'test')):\n",
    "        return load_data_from_train_test(mode)\n",
    "    else:\n",
    "        return load_data_from_categorical_folders()\n",
    "\n",
    "def load_data_from_annotation():\n",
    "    \n",
    "    args = parse_args()\n",
    "    img_col = args.img_size\n",
    "    img_row = args.img_size\n",
    "\n",
    "    data_path = os.path.join(os.getcwd(),'data',args.train_data)\n",
    "\n",
    "    text_file = os.path.join(data_path, 'annotation.txt')\n",
    "    train_data = [i.strip('\\n').split('\\t') for i in open(text_file)]\n",
    "    num_data = len(train_data)\n",
    "\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    \n",
    "    idxs = range(num_data)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(idxs)\n",
    "    idx_count = 0\n",
    "    for idx in tqdm(idxs):\n",
    "        img_path = train_data[idx][0]\n",
    "        label    = train_data[idx][1][:-1] # remove \\r\n",
    "        img_path = os.path.join(os.getcwd(), 'data', args.train_data, img_path)\n",
    "        img = imread(img_path, mode='RGB')\n",
    "        if img.nbytes > 10**3: # Read image file only when its size is larger than 1 kilo bytes\n",
    "            img = imresize(img, (img_col, img_row, 3))\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    data = {'Image': imgs,\n",
    "            'Label': labels}\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_data_from_categorical_folders():\n",
    "\n",
    "    args = parse_args()\n",
    "    img_col = args.img_size\n",
    "    img_row = args.img_size\n",
    "    \n",
    "    img_files = []\n",
    "    labels = []\n",
    "    \n",
    "    data_path = os.path.join(os.getcwd(), 'data', args.train_data)\n",
    "    category_idx = 0\n",
    "\n",
    "    print 'Loading files from data folder'\n",
    "    for category in tqdm(os.listdir(data_path)): # categorical subfolders in data folder\n",
    "        img_path = os.path.join(data_path, category)\n",
    "        img_count = 0\n",
    "        for img_file in os.listdir(img_path):\n",
    "            is_image = (img_file.endswith('png') or\n",
    "                        img_file.endswith('PNG') or\n",
    "                        img_file.endswith('jpg') or\n",
    "                        img_file.endswith('JPG') or\n",
    "                        img_file.endswith('jpeg') or\n",
    "                        img_file.endswith('JPEG') or\n",
    "                        img_file.endswith('gif') or\n",
    "                        img_file.endswith('GIF') or\n",
    "                        img_file.endswith('tif') or\n",
    "                        img_file.endswith('TIF'))\n",
    "                        \n",
    "            if is_image:\n",
    "                img_count += 1\n",
    "                img_files.append(os.path.join(img_path, img_file))\n",
    "                labels.append(category)\n",
    "\n",
    "        subcategory = [os.path.join(img_path, subfolder) for subfolder in os.listdir(img_path) if os.path.isdir(os.path.join(img_path,subfolder))]\n",
    "        for subcat in subcategory:\n",
    "            sub_path = os.path.join(img_path, subcat)\n",
    "            for img_file in os.listdir(sub_path):\n",
    "                is_image = (img_file.endswith('png') or\n",
    "                            img_file.endswith('PNG') or\n",
    "                            img_file.endswith('jpg') or\n",
    "                            img_file.endswith('JPG') or\n",
    "                            img_file.endswith('jpeg') or\n",
    "                            img_file.endswith('JPEG') or\n",
    "                            img_file.endswith('gif') or\n",
    "                            img_file.endswith('GIF') or\n",
    "                            img_file.endswith('tif') or\n",
    "                            img_file.endswith('TIF'))\n",
    "                if is_image:\n",
    "                    img_count += 1\n",
    "                    img_files.append(os.path.join(img_path, img_file))\n",
    "                    labels.append(category)\n",
    "    imgs = []\n",
    "    new_labels = []\n",
    "    num_data = len(img_files)\n",
    "    idxs = range(num_data)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(idxs)\n",
    "    print 'Image reading from files'\n",
    "    for idx in tqdm(idxs):\n",
    "        img_path = img_files[idx]\n",
    "        label    = labels[idx]\n",
    "        img = imread(img_path, mode='RGB')\n",
    "        if img.nbytes > 10**3: # Read image file only when its size is larger than 1 kilo bytes\n",
    "            img = imresize(img, (img_col, img_row, 3))\n",
    "            imgs.append(img)\n",
    "            new_labels.append(label)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    data = {'Image': imgs,\n",
    "            'Label': new_labels}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_data_from_train_test(mode='train'):\n",
    "\n",
    "    args = parse_args()\n",
    "    img_col = args.img_size\n",
    "    img_row = args.img_size\n",
    "    \n",
    "    img_files = []\n",
    "    labels = []\n",
    "    \n",
    "    data_path = os.path.join(os.getcwd(), 'data', args.train_data, mode)\n",
    "    category_idx = 0\n",
    "\n",
    "    print 'Loading files from data folder'\n",
    "    for category in tqdm(os.listdir(data_path)): # categorical subfolders in data folder\n",
    "        img_path = os.path.join(data_path, category)\n",
    "        img_count = 0\n",
    "        for img_file in os.listdir(img_path):\n",
    "            is_image = (img_file.endswith('png') or\n",
    "                        img_file.endswith('PNG') or\n",
    "                        img_file.endswith('jpg') or\n",
    "                        img_file.endswith('JPG') or\n",
    "                        img_file.endswith('jpeg') or\n",
    "                        img_file.endswith('JPEG') or\n",
    "                        img_file.endswith('gif') or\n",
    "                        img_file.endswith('GIF') or\n",
    "                        img_file.endswith('tif') or\n",
    "                        img_file.endswith('TIF'))\n",
    "                        \n",
    "            if is_image:\n",
    "                img_count += 1\n",
    "                img_files.append(os.path.join(img_path, img_file))\n",
    "                labels.append(category)\n",
    "\n",
    "        subcategory = [os.path.join(img_path, subfolder) for subfolder in os.listdir(img_path) if os.path.isdir(os.path.join(img_path,subfolder))]\n",
    "        for subcat in subcategory:\n",
    "            sub_path = os.path.join(img_path, subcat)\n",
    "            for img_file in os.listdir(sub_path):\n",
    "                is_image = (img_file.endswith('png') or\n",
    "                            img_file.endswith('PNG') or\n",
    "                            img_file.endswith('jpg') or\n",
    "                            img_file.endswith('JPG') or\n",
    "                            img_file.endswith('jpeg') or\n",
    "                            img_file.endswith('JPEG') or\n",
    "                            img_file.endswith('gif') or\n",
    "                            img_file.endswith('GIF') or\n",
    "                            img_file.endswith('tif') or\n",
    "                            img_file.endswith('TIF'))\n",
    "                if is_image:\n",
    "                    img_count += 1\n",
    "                    img_files.append(os.path.join(img_path, img_file))\n",
    "                    labels.append(category)\n",
    "    imgs = []\n",
    "    new_labels = []\n",
    "    num_data = len(img_files)\n",
    "    idxs = range(num_data)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(idxs)\n",
    "    print 'Image reading from files'\n",
    "    for idx in tqdm(idxs):\n",
    "        img_path = img_files[idx]\n",
    "        label    = labels[idx]\n",
    "        img = imread(img_path, mode='RGB')\n",
    "        if img.nbytes > 10**3: # Read image file only when its size is larger than 1 kilo bytes\n",
    "            img = imresize(img, (img_col, img_row, 3))\n",
    "            imgs.append(img)\n",
    "            new_labels.append(label)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    data = {'Image': imgs,\n",
    "            'Label': new_labels}\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def label_to_categorical(labels, label_dict=None, mode='to_categorical'):\n",
    "    if mode == 'to_categorical':\n",
    "        label_dict, ids = np.unique(labels, return_inverse=True)\n",
    "        output = to_categorical(ids, len(label_dict))\n",
    "    else:\n",
    "        output = label_dict[labels.argmax(1)]\n",
    "        output = output[0]\n",
    "    return output, label_dict\n",
    "\n",
    "def construct_data(frame):\n",
    "    args    = parse_args()\n",
    "    img_col = args.img_size\n",
    "    img_row = args.img_size\n",
    "    inputData   = np.asarray([im for im in frame['Image'].as_matrix()])\n",
    "    outputData, label_dict  = label_to_categorical(frame['Label'])\n",
    "    input_shape = (img_col, img_row, 3)\n",
    "    return inputData, outputData, input_shape, label_dict\n",
    "\n",
    "def get_model(input_shape, class_num):\n",
    "    args = parse_args()\n",
    "    \n",
    "    if args.model == 'resnet50':\n",
    "        model = ResNet50(include_top=True, weights=None,\n",
    "                         input_tensor=None, input_shape=input_shape,\n",
    "                         pooling=None, mode=args.mode,\n",
    "                         classes=class_num)\n",
    "        \n",
    "    elif args.model == 'resnet50_imagenet':\n",
    "        model = ResNet50(include_top=True, weights='imagenet',\n",
    "                         input_tensor=None, input_shape=input_shape,\n",
    "                         pooling=None, mode=args.mode,\n",
    "                         classes=class_num)\n",
    "        \n",
    "    elif args.model == 'pretrained':\n",
    "        modelName = os.path.join(os.getcwd(), 'weights', args.pretrained)\n",
    "        model = load_model(modelName)\n",
    "        \n",
    "    rmsprop = RMSprop(lr=1e-05, rho=0.99, epsilon=1e-08, decay=0.001)\n",
    "    model.compile(optimizer=rmsprop,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    print model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, batch_size=10):\n",
    "    args = parse_args()\n",
    "    epochs = args.epochs\n",
    "    validation_split = args.validation_split\n",
    "    weightDir = os.path.join(os.getcwd(), 'weights', args.model)\n",
    "    if not os.path.exists(weightDir):\n",
    "        os.makedirs(weightDir)\n",
    "    if validation_split > 0:\n",
    "        filepath = weightDir + '/weights.epoch_{epoch:02d}.val-loss_{val_loss:.2f}.h5'\n",
    "        modelChackpt = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                       monitor='val_loss',\n",
    "                                                       verbose=0,\n",
    "                                                       save_best_only=True,\n",
    "                                                       save_weights_only=False,\n",
    "                                                       mode='auto',\n",
    "                                                       period=10)\n",
    "    else:\n",
    "        filepath = weightDir + '/weights.epoch_{epoch:02d}.loss_{loss:.2f}.h5'\n",
    "        modelChackpt = keras.callbacks.ModelCheckpoint(filepath,\n",
    "                                                       monitor='loss',\n",
    "                                                       verbose=0,\n",
    "                                                       save_best_only=True,\n",
    "                                                       save_weights_only=False,\n",
    "                                                       mode='auto',\n",
    "                                                       period=10)\n",
    "        \n",
    "    time_start = datetime.now()\n",
    "    print '** Training Start, {}'.format(time_start.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    history = model.fit(inputData, outputData,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_split=validation_split,\n",
    "              shuffle=True,\n",
    "              callbacks=[modelChackpt])\n",
    "    time_end = datetime.now()\n",
    "    print '** Training Done, {}'.format(time_end.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    time_elapsed = str(time_end - time_start).split(':')\n",
    "    print '**** Elapsed Time : {} hours {} minutes'.format(time_elapsed[0], time_elapsed[1])\n",
    "    \n",
    "    modelName = os.path.join(os.getcwd(), 'weights', args.save)\n",
    "    model.save(modelName)\n",
    "    print '** Model Saved at [{}] ...'.format(modelName)\n",
    "\n",
    "def test_model(label_dict, sample_num=4):\n",
    "    print '**** Start testing the model'\n",
    "    args = parse_args()\n",
    "    img_col = args.img_size\n",
    "    img_row = args.img_size\n",
    "    validation_split = 1.0 - args.validation_split\n",
    "    \n",
    "    if validation_split == 1.0:\n",
    "        validation_split = 0.0\n",
    "    \n",
    "    modelName = os.path.join(os.getcwd(), 'weights', args.save)\n",
    "    model = load_model(modelName)\n",
    "    \n",
    "    num_data = len(frame['Label'])\n",
    "    \n",
    "    idxs = range(int(num_data*validation_split), num_data)\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(idxs)\n",
    "    if len(idxs) < sample_num:\n",
    "        sample_num = len(idxs)\n",
    "    print sample_num\n",
    "    idx_count = 0\n",
    "    right = 0\n",
    "    \n",
    "    fig_col  = int(np.ceil(sample_num/2.))\n",
    "    fig_row  = 2\n",
    "    fig_size = 6\n",
    "    f1 = plt.figure(figsize=(fig_row*fig_size, fig_col*fig_size))\n",
    "    \n",
    "    for idx in tqdm(idxs):\n",
    "        plt.subplot(fig_col,fig_row,idx_count+1)\n",
    "        plt.axis('off')\n",
    "        img = frame['Image'][idx]\n",
    "        input_img = np.reshape(img, (1, img_col, img_row, 3))\n",
    "        predict = model.predict(input_img)\n",
    "        \n",
    "        target_label = frame['Label'][idx]\n",
    "        predicted_label = label_to_categorical(predict,label_dict,'reverse')\n",
    "        predicted_label = predicted_label[0]\n",
    "        if predicted_label == target_label:\n",
    "            right += 1\n",
    "        plt.title('Groundtruth : {}\\nPredicted   : {}'.format(target_label, predicted_label))\n",
    "        _ = plt.imshow(img)\n",
    "        idx_count += 1\n",
    "        if idx_count >= sample_num:\n",
    "            break\n",
    "    print '** Accuracy : {} ({} / {})'.format(right*100./sample_num, right, idx_count)\n",
    "    plt.show()\n",
    "    now = datetime.now()\n",
    "    nowDatetime = now.strftime('%Y_%m_%d-%H%M%S')\n",
    "    imgResultFileName = os.path.join(os.getcwd(), 'result', nowDatetime + '_' + args.save + '.png')\n",
    "    f1.savefig(imgResultFileName, dpi=100)\n",
    "    print '**** Result Image Saved at [{}] ...'.format(imgResultFileName)\n",
    "\n",
    "args = parse_args()\n",
    "frame = load_data()\n",
    "inputData, outputData, input_shape, label_dict = construct_data(frame)\n",
    "\n",
    "model = get_model(input_shape=input_shape, class_num=len(outputData[0]))\n",
    "\n",
    "train_model(model)\n",
    "\n",
    "# uncomment if your data structure follows \"train_test\" format\n",
    "# frame = load_data(mode='test')\n",
    "# inputData, outputData, input_shape, label_dict = construct_data(frame)\n",
    "test_model(label_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
